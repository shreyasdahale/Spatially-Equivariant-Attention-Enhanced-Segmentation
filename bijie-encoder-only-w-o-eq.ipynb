{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-08T11:48:52.471512Z",
     "iopub.status.busy": "2025-01-08T11:48:52.471268Z",
     "iopub.status.idle": "2025-01-08T11:48:57.228873Z",
     "shell.execute_reply": "2025-01-08T11:48:57.228125Z",
     "shell.execute_reply.started": "2025-01-08T11:48:52.471484Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "from PIL import Image, ImageOps\n",
    "from skimage.util import random_noise\n",
    "from skimage import exposure\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, jaccard_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Helper functions`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-08T11:48:57.230056Z",
     "iopub.status.busy": "2025-01-08T11:48:57.229743Z",
     "iopub.status.idle": "2025-01-08T11:48:57.243613Z",
     "shell.execute_reply": "2025-01-08T11:48:57.242807Z",
     "shell.execute_reply.started": "2025-01-08T11:48:57.230037Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def add_gaussian_noise(image, mean=0, std=0.05):\n",
    "    np_image = np.array(image) / 255.0 \n",
    "    noisy_image = random_noise(np_image, mode='gaussian', mean=mean, var=std**2)\n",
    "    noisy_image = np.clip(noisy_image * 255, 0, 255).astype(np.uint8)\n",
    "    return Image.fromarray(noisy_image)\n",
    "\n",
    "def add_salt_pepper_noise(image, amount=0.02):\n",
    "    np_image = np.array(image) / 255.0\n",
    "    noisy_image = random_noise(np_image, mode='s&p', amount=amount)\n",
    "    noisy_image = np.clip(noisy_image * 255, 0, 255).astype(np.uint8)\n",
    "    return Image.fromarray(noisy_image)\n",
    "\n",
    "def histogram_equalization(image):\n",
    "    np_image = np.array(image)\n",
    "    equalized_image = exposure.equalize_hist(np_image) * 255 \n",
    "    equalized_image = equalized_image.astype(np.uint8)\n",
    "    return Image.fromarray(equalized_image)\n",
    "\n",
    "def augment_image(image, dem):\n",
    "    augmentations = [\n",
    "        ('original', None),\n",
    "        ('horizontal_flip', ImageOps.mirror),\n",
    "        ('vertical_flip', ImageOps.flip),\n",
    "        ('rotate_90', lambda img: img.rotate(90)),\n",
    "        ('gaussian_noise', add_gaussian_noise),\n",
    "        ('salt_pepper_noise', add_salt_pepper_noise),\n",
    "        ('hist_eq', histogram_equalization)\n",
    "    ]\n",
    "\n",
    "    augmentation = random.choice(augmentations)\n",
    "\n",
    "    if augmentation[0] == 'original':\n",
    "        return image, dem\n",
    "    elif augmentation[0] == 'horizontal_flip' or augmentation[0] == 'vertical_flip':\n",
    "        return augmentation[1](image), augmentation[1](dem)\n",
    "    elif augmentation[0] == 'rotate_90':\n",
    "        return augmentation[1](image), augmentation[1](dem)\n",
    "    elif augmentation[0] == 'gaussian_noise':\n",
    "        return augmentation[1](image), augmentation[1](dem)\n",
    "    elif augmentation[0] == 'salt_pepper_noise':\n",
    "        return augmentation[1](image), augmentation[1](dem)\n",
    "    elif augmentation[0] == 'hist_eq':\n",
    "        return augmentation[1](image), augmentation[1](dem)\n",
    "\n",
    "def load_image(image_path, target_size):\n",
    "    image = Image.open(image_path).convert('RGB' if target_size[2] == 3 else 'L')\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize(target_size[:2]),\n",
    "    ])\n",
    "    return transform(image)\n",
    "\n",
    "def load_real_data(data_dir, target_size=(256, 256)):\n",
    "    landslide_dir = os.path.join(data_dir, 'landslide')\n",
    "    non_landslide_dir = os.path.join(data_dir, 'non-landslide')\n",
    "\n",
    "    images = []\n",
    "    dems = []\n",
    "    labels = []\n",
    "\n",
    "    def process_and_augment(image_path, dem_path, label):\n",
    "        image = load_image(image_path, target_size + (3,))\n",
    "        dem = load_image(dem_path, target_size + (1,))\n",
    "\n",
    "        augmented_image, augmented_dem = augment_image(image, dem)\n",
    "\n",
    "        images.append(transforms.ToTensor()(image))  # Original image\n",
    "        dems.append(transforms.ToTensor()(dem))  # Original DEM\n",
    "        labels.append(label)\n",
    "\n",
    "        images.append(transforms.ToTensor()(augmented_image))\n",
    "        dems.append(transforms.ToTensor()(augmented_dem))\n",
    "        labels.append(label)\n",
    "\n",
    "    for filename in os.listdir(os.path.join(landslide_dir, 'image')):\n",
    "        if filename.endswith(\".png\"):\n",
    "            image_path = os.path.join(landslide_dir, 'image', filename)\n",
    "            dem_path = os.path.join(landslide_dir, 'dem', filename)\n",
    "            process_and_augment(image_path, dem_path, label=1)  # Label 1 for landslide\n",
    "\n",
    "    for filename in os.listdir(os.path.join(non_landslide_dir, 'image')):\n",
    "        if filename.endswith(\".png\"):\n",
    "            image_path = os.path.join(non_landslide_dir, 'image', filename)\n",
    "            dem_path = os.path.join(non_landslide_dir, 'dem', filename)\n",
    "            process_and_augment(image_path, dem_path, label=0)  # Label 0 for non-landslide\n",
    "\n",
    "    images = torch.stack(images)\n",
    "    dems = torch.stack(dems)\n",
    "    labels = torch.tensor(labels, dtype=torch.float32)\n",
    "\n",
    "    return images, dems, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Network components`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-08T12:03:24.586624Z",
     "iopub.status.busy": "2025-01-08T12:03:24.586253Z",
     "iopub.status.idle": "2025-01-08T12:03:24.593435Z",
     "shell.execute_reply": "2025-01-08T12:03:24.592392Z",
     "shell.execute_reply.started": "2025-01-08T12:03:24.586597Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(ConvBlock, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "        \n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.conv1_rgb = ConvBlock(3, 16)\n",
    "        self.conv1_dem = ConvBlock(1, 8)\n",
    "        self.conv2 = ConvBlock(24, 32)\n",
    "        self.conv3 = ConvBlock(32, 64)\n",
    "        self.conv4 = ConvBlock(64, 128)\n",
    "        self.bottleneck = ConvBlock(128, 256)\n",
    "        \n",
    "        self.global_pool = nn.AdaptiveAvgPool2d(1) \n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Flatten(),           \n",
    "            nn.Linear(256, 1),       \n",
    "            nn.Sigmoid()              \n",
    "        )\n",
    "\n",
    "    def forward(self, x_rgb, x_dem):\n",
    "        c1_rgb = self.conv1_rgb(x_rgb)\n",
    "        c1_dem = self.conv1_dem(x_dem)\n",
    "        combined = torch.cat([c1_rgb, c1_dem], dim=1)\n",
    "\n",
    "        c2 = self.conv2(combined)\n",
    "        p2 = nn.MaxPool2d(kernel_size=2)(c2)\n",
    "\n",
    "        c3 = self.conv3(p2)\n",
    "        p3 = nn.MaxPool2d(kernel_size=2)(c3)\n",
    "\n",
    "        c4 = self.conv4(p3)\n",
    "        p4 = nn.MaxPool2d(kernel_size=2)(c4)\n",
    "\n",
    "        bn = self.bottleneck(p4)\n",
    "        pooled = self.global_pool(bn)  \n",
    "        return self.fc(pooled)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-08T11:48:57.266296Z",
     "iopub.status.busy": "2025-01-08T11:48:57.266078Z",
     "iopub.status.idle": "2025-01-08T11:48:57.330331Z",
     "shell.execute_reply": "2025-01-08T11:48:57.329357Z",
     "shell.execute_reply.started": "2025-01-08T11:48:57.266268Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-08T11:48:57.331721Z",
     "iopub.status.busy": "2025-01-08T11:48:57.331365Z",
     "iopub.status.idle": "2025-01-08T11:49:59.224459Z",
     "shell.execute_reply": "2025-01-08T11:49:59.223785Z",
     "shell.execute_reply.started": "2025-01-08T11:48:57.331665Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "data_dir = '/kaggle/input/bijie/Bijie_dataset'\n",
    "images, dems, labels = load_real_data(data_dir, target_size=(256, 256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-08T11:50:18.167180Z",
     "iopub.status.busy": "2025-01-08T11:50:18.166835Z",
     "iopub.status.idle": "2025-01-08T11:50:18.173165Z",
     "shell.execute_reply": "2025-01-08T11:50:18.172298Z",
     "shell.execute_reply.started": "2025-01-08T11:50:18.167151Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "len(dems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-08T11:50:42.082288Z",
     "iopub.status.busy": "2025-01-08T11:50:42.081924Z",
     "iopub.status.idle": "2025-01-08T11:50:44.196851Z",
     "shell.execute_reply": "2025-01-08T11:50:44.196065Z",
     "shell.execute_reply.started": "2025-01-08T11:50:42.082259Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train_img, X_test_img, X_train_dem, X_test_dem, y_train, y_test = train_test_split(\n",
    "    images, dems, labels, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(X_train_img.shape, X_train_dem[0].shape, y_train[0].shape)\n",
    "print(\"Training data size:\", len(X_train_img))\n",
    "print(\"Testing data size:\", len(X_test_img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-08T11:55:23.297211Z",
     "iopub.status.busy": "2025-01-08T11:55:23.296917Z",
     "iopub.status.idle": "2025-01-08T11:55:23.303126Z",
     "shell.execute_reply": "2025-01-08T11:55:23.302109Z",
     "shell.execute_reply.started": "2025-01-08T11:55:23.297190Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, images, dems, masks):\n",
    "        self.images = images\n",
    "        self.dems = dems\n",
    "        self.masks = masks\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'image': self.images[idx],\n",
    "            'dem': self.dems[idx],\n",
    "            'label': self.masks[idx]\n",
    "        }\n",
    "\n",
    "train_dataset = CustomDataset(X_train_img, X_train_dem, y_train)\n",
    "val_dataset = CustomDataset(X_test_img, X_test_dem, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-08T12:03:57.663114Z",
     "iopub.status.busy": "2025-01-08T12:03:57.662797Z",
     "iopub.status.idle": "2025-01-08T12:03:57.683326Z",
     "shell.execute_reply": "2025-01-08T12:03:57.682618Z",
     "shell.execute_reply.started": "2025-01-08T12:03:57.663088Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model = Encoder()#.to(device)\n",
    "epochs = 200\n",
    "best_val_loss = float('inf')\n",
    "best_model_path = 'best_unet_model.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parameters: 1184009\n"
     ]
    }
   ],
   "source": [
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Total parameters: {total_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-01-08T12:16:46.007Z",
     "iopub.execute_input": "2025-01-08T12:14:12.326070Z",
     "iopub.status.busy": "2025-01-08T12:14:12.325733Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5, verbose=True)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "\n",
    "    for batch in train_loader:\n",
    "        images = batch['image'].to(device)\n",
    "        dems = batch['dem'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images, dems).squeeze(1) \n",
    "\n",
    "        binary_preds = (outputs > 0.5).float()\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    train_loss /= len(train_loader)\n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            images = batch['image'].to(device)\n",
    "            dems = batch['dem'].to(device)\n",
    "            labels = batch['label'].to(device)\n",
    "\n",
    "            outputs = model(images, dems).squeeze(1)\n",
    "\n",
    "            binary_preds = (outputs > 0.5).float()\n",
    "\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            preds = binary_preds.cpu().numpy().astype(int)\n",
    "            targets = labels.cpu().numpy().astype(int)\n",
    "            all_preds.append(preds)\n",
    "            all_targets.append(targets)\n",
    "\n",
    "    val_loss /= len(val_loader)\n",
    "\n",
    "    all_preds = np.concatenate([pred.flatten() for pred in all_preds])\n",
    "    all_targets = np.concatenate([target.flatten() for target in all_targets])\n",
    "\n",
    "    accuracy = accuracy_score(all_targets, all_preds)\n",
    "    precision = precision_score(all_targets, all_preds, zero_division=0)\n",
    "    recall = recall_score(all_targets, all_preds, zero_division=0)\n",
    "    f1 = f1_score(all_targets, all_preds)\n",
    "    iou = jaccard_score(all_targets, all_preds)\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}/{epochs}, Train Loss: {train_loss}, Val Loss: {val_loss}, Accuracy: {accuracy}, Precision: {precision}, Recall: {recall}, IoU: {iou}, F1: {f1}\")\n",
    "\n",
    "    scheduler.step(val_loss)\n",
    "\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save(model.state_dict(), best_model_path)\n",
    "        print(f\"Saved best model with val loss: {best_val_loss}\")\n",
    "\n",
    "print(\"Training complete. Best model saved to\", best_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "model = Encoder().to(device)\n",
    "summary(model, input_size=[(1, 3, 256, 256), (1, 1, 256, 256)]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 6398811,
     "sourceId": 10334130,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30823,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
