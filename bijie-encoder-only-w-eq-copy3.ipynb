{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-12T14:44:02.381061Z",
     "iopub.status.busy": "2025-01-12T14:44:02.380751Z",
     "iopub.status.idle": "2025-01-12T14:44:22.723294Z",
     "shell.execute_reply": "2025-01-12T14:44:22.722258Z",
     "shell.execute_reply.started": "2025-01-12T14:44:02.381038Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting escnn\n",
      "  Downloading escnn-1.0.11-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: torch>=1.3 in /usr/local/lib/python3.10/dist-packages (from escnn) (2.4.1+cu121)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from escnn) (1.26.4)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from escnn) (1.13.1)\n",
      "Collecting lie-learn (from escnn)\n",
      "  Downloading lie_learn-0.0.2-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.3 kB)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from escnn) (1.4.2)\n",
      "Collecting pymanopt (from escnn)\n",
      "  Downloading pymanopt-2.2.1-py3-none-any.whl.metadata (7.0 kB)\n",
      "Requirement already satisfied: autograd in /usr/local/lib/python3.10/dist-packages (from escnn) (1.7.0)\n",
      "Collecting py3nj (from escnn)\n",
      "  Downloading py3nj-0.2.1.tar.gz (49 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.0/50.0 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
      "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->escnn) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->escnn) (4.12.2)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->escnn) (1.13.3)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->escnn) (3.3)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->escnn) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->escnn) (2024.6.1)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from lie-learn->escnn) (2.32.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.3->escnn) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->lie-learn->escnn) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->lie-learn->escnn) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->lie-learn->escnn) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->lie-learn->escnn) (2024.8.30)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.3->escnn) (1.3.0)\n",
      "Downloading escnn-1.0.11-py3-none-any.whl (373 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m373.9/373.9 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading lie_learn-0.0.2-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.5/16.5 MB\u001b[0m \u001b[31m92.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading pymanopt-2.2.1-py3-none-any.whl (71 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: py3nj\n",
      "  Building wheel for py3nj (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for py3nj: filename=py3nj-0.2.1-cp310-cp310-linux_x86_64.whl size=44764 sha256=802ba101a5851cb19cfb047550a72b0023f3e86678b8464b5001cdbf3dbae8dd\n",
      "  Stored in directory: /root/.cache/pip/wheels/71/e9/70/30a34ed6dbc8b54ce93f25c091be4cf7a24319e27d953a882b\n",
      "Successfully built py3nj\n",
      "Installing collected packages: py3nj, pymanopt, lie-learn, escnn\n",
      "Successfully installed escnn-1.0.11 lie-learn-0.0.2 py3nj-0.2.1 pymanopt-2.2.1\n"
     ]
    }
   ],
   "source": [
    "!pip install escnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-12T14:45:31.901514Z",
     "iopub.status.busy": "2025-01-12T14:45:31.900842Z",
     "iopub.status.idle": "2025-01-12T14:45:31.906818Z",
     "shell.execute_reply": "2025-01-12T14:45:31.905994Z",
     "shell.execute_reply.started": "2025-01-12T14:45:31.901479Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "from escnn.gspaces import flipRot2dOnR2\n",
    "from escnn.nn import FieldType, R2Conv, NormBatchNorm, ReLU, SequentialModule, EquivariantModule, FieldType, GeometricTensor, InnerBatchNorm, PointwiseMaxPool2D\n",
    "from PIL import Image, ImageOps\n",
    "from skimage.util import random_noise\n",
    "from skimage import exposure\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, jaccard_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Helper functions`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-12T14:45:33.903931Z",
     "iopub.status.busy": "2025-01-12T14:45:33.903631Z",
     "iopub.status.idle": "2025-01-12T14:45:33.911423Z",
     "shell.execute_reply": "2025-01-12T14:45:33.910741Z",
     "shell.execute_reply.started": "2025-01-12T14:45:33.903906Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def load_image(image_path, target_size):\n",
    "    image = Image.open(image_path).convert('RGB' if target_size[2] == 3 else 'L')\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize(target_size[:2]),\n",
    "    ])\n",
    "    return transform(image)\n",
    "\n",
    "def load_real_data(data_dir, target_size=(256, 256)):\n",
    "    landslide_dir = os.path.join(data_dir, 'landslide')\n",
    "    non_landslide_dir = os.path.join(data_dir, 'non-landslide')\n",
    "\n",
    "    images = []\n",
    "    dems = []\n",
    "    labels = []\n",
    "\n",
    "    def process_image(image_path, dem_path, label):\n",
    "        image = load_image(image_path, target_size + (3,))\n",
    "        dem = load_image(dem_path, target_size + (1,))\n",
    "\n",
    "        images.append(transforms.ToTensor()(image))\n",
    "        dems.append(transforms.ToTensor()(dem))\n",
    "        labels.append(label)\n",
    "\n",
    "    for filename in os.listdir(os.path.join(landslide_dir, 'image')):\n",
    "        if filename.endswith(\".png\"):\n",
    "            image_path = os.path.join(landslide_dir, 'image', filename)\n",
    "            dem_path = os.path.join(landslide_dir, 'dem', filename)\n",
    "            process_image(image_path, dem_path, label=1)\n",
    "\n",
    "    for filename in os.listdir(os.path.join(non_landslide_dir, 'image')):\n",
    "        if filename.endswith(\".png\"):\n",
    "            image_path = os.path.join(non_landslide_dir, 'image', filename)\n",
    "            dem_path = os.path.join(non_landslide_dir, 'dem', filename)\n",
    "            process_image(image_path, dem_path, label=0)\n",
    "\n",
    "    images = torch.stack(images)\n",
    "    dems = torch.stack(dems)\n",
    "    labels = torch.tensor(labels, dtype=torch.float32)\n",
    "\n",
    "    return images, dems, labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Network components`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-12T14:45:50.587718Z",
     "iopub.status.busy": "2025-01-12T14:45:50.587397Z",
     "iopub.status.idle": "2025-01-12T14:45:50.600297Z",
     "shell.execute_reply": "2025-01-12T14:45:50.599531Z",
     "shell.execute_reply.started": "2025-01-12T14:45:50.587691Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class ConvBlock1(EquivariantModule):\n",
    "    def __init__(self, space, in_channels, out_channels):\n",
    "        super(ConvBlock1, self).__init__()\n",
    "        self.space = space\n",
    "        group_size = len(self.space.fibergroup.elements)\n",
    "        self.in_type = FieldType(self.space, [self.space.trivial_repr] * in_channels)\n",
    "        self.out_type = FieldType(self.space, [self.space.regular_repr] * out_channels)\n",
    "\n",
    "        self.conv = SequentialModule(\n",
    "            R2Conv(self.in_type, self.out_type, kernel_size=3, padding=1, bias=False),\n",
    "            InnerBatchNorm(self.out_type),\n",
    "            ReLU(self.out_type),\n",
    "            R2Conv(self.out_type, self.out_type, kernel_size=3, padding=1, bias=False),\n",
    "            InnerBatchNorm(self.out_type),\n",
    "            ReLU(self.out_type)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        if not isinstance(x, GeometricTensor):\n",
    "            geo_x = GeometricTensor(x, self.in_type)\n",
    "        else:\n",
    "            geo_x = x\n",
    "        return self.conv(geo_x)\n",
    "\n",
    "    def evaluate_output_shape(self, input_shape):\n",
    "        return self.conv.evaluate_output_shape(input_shape)\n",
    "\n",
    "\n",
    "class ConvBlock(EquivariantModule):\n",
    "    def __init__(self, space, in_channels, out_channels):\n",
    "        super(ConvBlock, self).__init__()\n",
    "        self.space = space\n",
    "        group_size = len(self.space.fibergroup.elements)\n",
    "        self.in_type = FieldType(self.space, [self.space.regular_repr] * in_channels)\n",
    "        self.out_type = FieldType(self.space, [self.space.regular_repr] * out_channels)\n",
    "\n",
    "        self.conv = SequentialModule(\n",
    "            R2Conv(self.in_type, self.out_type, kernel_size=3, padding=1, bias=False),\n",
    "            InnerBatchNorm(self.out_type),\n",
    "            ReLU(self.out_type),\n",
    "            R2Conv(self.out_type, self.out_type, kernel_size=3, padding=1, bias=False),\n",
    "            InnerBatchNorm(self.out_type),\n",
    "            ReLU(self.out_type)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        if not isinstance(x, GeometricTensor):\n",
    "            geo_x = GeometricTensor(x, self.in_type)\n",
    "        else:\n",
    "            geo_x = x\n",
    "        return self.conv(geo_x)\n",
    "\n",
    "    def evaluate_output_shape(self, input_shape):\n",
    "        return self.conv.evaluate_output_shape(input_shape)\n",
    "        \n",
    "\n",
    "class Encoder(EquivariantModule):\n",
    "    def __init__(self):\n",
    "        super(Encoder, self).__init__()\n",
    "        # p4m\n",
    "        self.space = flipRot2dOnR2(4)\n",
    "\n",
    "        self.conv1_rgb = ConvBlock1(self.space, 3, 16)\n",
    "        self.conv1_dem = ConvBlock1(self.space, 1, 8)        \n",
    "        self.conv2 = ConvBlock(self.space, 24, 32)\n",
    "        self.conv3 = ConvBlock(self.space, 32, 64)\n",
    "        self.conv4 = ConvBlock(self.space, 64, 128)\n",
    "        self.bottleneck = ConvBlock(self.space, 128, 256)\n",
    "\n",
    "        self.pool2 = PointwiseMaxPool2D(in_type=self.conv2.out_type, kernel_size=2)\n",
    "        self.pool3 = PointwiseMaxPool2D(in_type=self.conv3.out_type, kernel_size=2)\n",
    "        self.pool4 = PointwiseMaxPool2D(in_type=self.conv4.out_type, kernel_size=2)\n",
    "\n",
    "        self.global_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        \n",
    "        # fc\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            # nn.Linear(2048, 256),\n",
    "            nn.Linear(2048, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x_rgb, x_dem):\n",
    "        c1_rgb = self.conv1_rgb(x_rgb)\n",
    "        c1_dem = self.conv1_dem(x_dem)\n",
    "\n",
    "        combined = torch.cat([c1_rgb.tensor, c1_dem.tensor], dim=1)\n",
    "\n",
    "        c2 = self.conv2(combined)\n",
    "        p2 = self.pool2(c2)\n",
    "\n",
    "        c3 = self.conv3(p2)\n",
    "        p3 = self.pool3(c3)\n",
    "\n",
    "        c4 = self.conv4(p3)\n",
    "        p4 = self.pool4(c4)\n",
    "\n",
    "        bn = self.bottleneck(p4)\n",
    "        pooled = self.global_pool(bn.tensor)\n",
    "\n",
    "        return self.fc(pooled)\n",
    "\n",
    "    def evaluate_output_shape(self, input_shape):\n",
    "        raise NotImplementedError(\"Shape evaluation not implemented yet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# from torchinfo import summary\n",
    "\n",
    "# model = Encoder().to(device)\n",
    "# summary(model, input_size=[(1, 3, 256, 256), (1, 1, 256, 256)]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-12T14:46:01.975717Z",
     "iopub.status.busy": "2025-01-12T14:46:01.975399Z",
     "iopub.status.idle": "2025-01-12T14:46:02.033234Z",
     "shell.execute_reply": "2025-01-12T14:46:02.032394Z",
     "shell.execute_reply.started": "2025-01-12T14:46:01.975695Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-12T14:46:31.726068Z",
     "iopub.status.busy": "2025-01-12T14:46:31.725712Z",
     "iopub.status.idle": "2025-01-12T14:47:47.352058Z",
     "shell.execute_reply": "2025-01-12T14:47:47.351083Z",
     "shell.execute_reply.started": "2025-01-12T14:46:31.726038Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "data_dir = '/kaggle/input/bijie/Bijie_dataset'\n",
    "images, dems, labels = load_real_data(data_dir, target_size=(256, 256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-12T14:47:56.716560Z",
     "iopub.status.busy": "2025-01-12T14:47:56.716275Z",
     "iopub.status.idle": "2025-01-12T14:47:56.722391Z",
     "shell.execute_reply": "2025-01-12T14:47:56.721560Z",
     "shell.execute_reply.started": "2025-01-12T14:47:56.716540Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2773"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-12T14:48:01.376584Z",
     "iopub.status.busy": "2025-01-12T14:48:01.376288Z",
     "iopub.status.idle": "2025-01-12T14:48:02.513849Z",
     "shell.execute_reply": "2025-01-12T14:48:02.513032Z",
     "shell.execute_reply.started": "2025-01-12T14:48:01.376562Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2218, 3, 256, 256]) torch.Size([1, 256, 256]) torch.Size([])\n",
      "Training data size: 2218\n",
      "Testing data size: 555\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train_img, X_test_img, X_train_dem, X_test_dem, y_train, y_test = train_test_split(\n",
    "    images, dems, labels, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(X_train_img.shape, X_train_dem[0].shape, y_train[0].shape)\n",
    "print(\"Training data size:\", len(X_train_img))\n",
    "print(\"Testing data size:\", len(X_test_img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-12T14:48:04.196579Z",
     "iopub.status.busy": "2025-01-12T14:48:04.196296Z",
     "iopub.status.idle": "2025-01-12T14:48:04.202119Z",
     "shell.execute_reply": "2025-01-12T14:48:04.201227Z",
     "shell.execute_reply.started": "2025-01-12T14:48:04.196559Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, images, dems, masks):\n",
    "        self.images = images\n",
    "        self.dems = dems\n",
    "        self.masks = masks\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'image': self.images[idx],\n",
    "            'dem': self.dems[idx],\n",
    "            'label': self.masks[idx]\n",
    "        }\n",
    "\n",
    "train_dataset = CustomDataset(X_train_img, X_train_dem, y_train)\n",
    "val_dataset = CustomDataset(X_test_img, X_test_dem, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-12T14:48:13.412413Z",
     "iopub.status.busy": "2025-01-12T14:48:13.412099Z",
     "iopub.status.idle": "2025-01-12T14:49:07.843443Z",
     "shell.execute_reply": "2025-01-12T14:49:07.842483Z",
     "shell.execute_reply.started": "2025-01-12T14:48:13.412391Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model = Encoder().to(device)\n",
    "epochs = 200\n",
    "best_val_loss = float('inf')\n",
    "best_model_path = 'best_unet_model.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-12T14:49:14.249164Z",
     "iopub.status.busy": "2025-01-12T14:49:14.248830Z",
     "iopub.status.idle": "2025-01-12T14:49:14.265780Z",
     "shell.execute_reply": "2025-01-12T14:49:14.265102Z",
     "shell.execute_reply.started": "2025-01-12T14:49:14.249112Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parameters: 6298929\n"
     ]
    }
   ],
   "source": [
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Total parameters: {total_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-01-12T14:53:41.800Z",
     "iopub.execute_input": "2025-01-12T14:49:20.968784Z",
     "iopub.status.busy": "2025-01-12T14:49:20.968485Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200, Train Loss: 0.17488688565522648, Val Loss: 0.13884031176567077, Accuracy: 0.8054054054054054, Precision: 0.6935483870967742, Recall: 0.5512820512820513, IoU: 0.44329896907216493, F1: 0.6142857142857143\n",
      "Saved best model with val loss: 0.13884031176567077\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.MSELoss()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5, verbose=True)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "\n",
    "    for batch in train_loader:\n",
    "        images = batch['image'].to(device)\n",
    "        dems = batch['dem'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images, dems).squeeze(1) \n",
    "\n",
    "        binary_preds = (outputs > 0.5).float()\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    train_loss /= len(train_loader)\n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            images = batch['image'].to(device)\n",
    "            dems = batch['dem'].to(device)\n",
    "            labels = batch['label'].to(device)\n",
    "\n",
    "            outputs = model(images, dems).squeeze(1)\n",
    "\n",
    "            binary_preds = (outputs > 0.5).float()\n",
    "\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            preds = binary_preds.cpu().numpy().astype(int)\n",
    "            targets = labels.cpu().numpy().astype(int)\n",
    "            all_preds.append(preds)\n",
    "            all_targets.append(targets)\n",
    "\n",
    "    val_loss /= len(val_loader)\n",
    "\n",
    "    all_preds = np.concatenate([pred.flatten() for pred in all_preds])\n",
    "    all_targets = np.concatenate([target.flatten() for target in all_targets])\n",
    "\n",
    "    accuracy = accuracy_score(all_targets, all_preds)\n",
    "    precision = precision_score(all_targets, all_preds, zero_division=0)\n",
    "    recall = recall_score(all_targets, all_preds, zero_division=0)\n",
    "    f1 = f1_score(all_targets, all_preds)\n",
    "    iou = jaccard_score(all_targets, all_preds)\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}/{epochs}, Train Loss: {train_loss}, Val Loss: {val_loss}, Accuracy: {accuracy}, Precision: {precision}, Recall: {recall}, IoU: {iou}, F1: {f1}\")\n",
    "\n",
    "    scheduler.step(val_loss)\n",
    "\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save(model.state_dict(), best_model_path)\n",
    "        print(f\"Saved best model with val loss: {best_val_loss}\")\n",
    "\n",
    "print(\"Training complete. Best model saved to\", best_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 6398811,
     "sourceId": 10334130,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30823,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
