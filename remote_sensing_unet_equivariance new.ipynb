{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f21d8657-b94b-4d13-8e6e-9d893eb8ce74",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-30T15:53:39.897534Z",
     "iopub.status.busy": "2024-12-30T15:53:39.897243Z",
     "iopub.status.idle": "2024-12-30T15:53:44.561282Z",
     "shell.execute_reply": "2024-12-30T15:53:44.560517Z",
     "shell.execute_reply.started": "2024-12-30T15:53:39.897511Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, jaccard_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88219d44-4650-4447-8e49-72109fc105db",
   "metadata": {},
   "source": [
    "`Helper functions`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07f0578d-8a19-4181-b958-6ec42f617c04",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-30T15:53:44.562766Z",
     "iopub.status.busy": "2024-12-30T15:53:44.562369Z",
     "iopub.status.idle": "2024-12-30T15:53:44.570825Z",
     "shell.execute_reply": "2024-12-30T15:53:44.570147Z",
     "shell.execute_reply.started": "2024-12-30T15:53:44.562717Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def load_image(image_path, target_size):\n",
    "    image = Image.open(image_path).convert('RGB' if target_size[2] == 3 else 'L')\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize(target_size[:2]),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "    return transform(image)\n",
    "\n",
    "def load_real_data(data_dir, target_size=(256, 256)):\n",
    "    landslide_dir = os.path.join(data_dir, 'landslide')\n",
    "    non_landslide_dir = os.path.join(data_dir, 'non-landslide')\n",
    "\n",
    "    images = []\n",
    "    dems = []\n",
    "    masks = []\n",
    "\n",
    "    # Load landslide data\n",
    "    for filename in os.listdir(os.path.join(landslide_dir, 'image')):\n",
    "        if filename.endswith(\".png\"):\n",
    "            image_path = os.path.join(landslide_dir, 'image', filename)\n",
    "            dem_path = os.path.join(landslide_dir, 'dem', filename)\n",
    "            mask_path = os.path.join(landslide_dir, 'mask', filename)\n",
    "\n",
    "            image = load_image(image_path, target_size + (3,))  # RGB (C=3)\n",
    "            dem = load_image(dem_path, target_size + (1,))      # Grayscale (C=1)\n",
    "            mask = load_image(mask_path, target_size + (1,))    # Grayscale (C=1)\n",
    "\n",
    "            images.append(image)\n",
    "            dems.append(dem)\n",
    "            masks.append(mask)\n",
    "\n",
    "    # Load non-landslide data\n",
    "    for filename in os.listdir(os.path.join(non_landslide_dir, 'image')):\n",
    "        if filename.endswith(\".png\"):\n",
    "            image_path = os.path.join(non_landslide_dir, 'image', filename)\n",
    "            dem_path = os.path.join(non_landslide_dir, 'dem', filename)\n",
    "\n",
    "            image = load_image(image_path, target_size + (3,))  # RGB (C=3)\n",
    "            dem = load_image(dem_path, target_size + (1,))      # Grayscale (C=1)\n",
    "            mask = torch.zeros((1, *target_size), dtype=torch.float32)  # Mask is all zeros, (C=1)\n",
    "\n",
    "            images.append(image)\n",
    "            dems.append(dem)\n",
    "            masks.append(mask)\n",
    "\n",
    "    # Stack tensors\n",
    "    images = torch.stack(images)\n",
    "    dems = torch.stack(dems)\n",
    "    masks = torch.stack(masks)\n",
    "\n",
    "    return images, dems, masks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ee88b3-9554-42ff-adf1-99321430f254",
   "metadata": {},
   "source": [
    "`Network components`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d04895d2-319e-4a00-89e7-3134298e8a4b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-30T15:53:44.572383Z",
     "iopub.status.busy": "2024-12-30T15:53:44.572186Z",
     "iopub.status.idle": "2024-12-30T15:53:44.593998Z",
     "shell.execute_reply": "2024-12-30T15:53:44.593218Z",
     "shell.execute_reply.started": "2024-12-30T15:53:44.572366Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(ConvBlock, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "class AttentionBlock(nn.Module):\n",
    "    def __init__(self, in_channels, skip_channels):\n",
    "        super(AttentionBlock, self).__init__()\n",
    "        self.g1 = nn.Conv2d(in_channels, skip_channels, kernel_size=1)\n",
    "        self.x1 = nn.Conv2d(skip_channels, skip_channels, kernel_size=1)\n",
    "        self.psi = nn.Conv2d(skip_channels, 1, kernel_size=1)\n",
    "        self.upsample = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x, skip):\n",
    "        # Upsample g1 to match the spatial dimensions of skip\n",
    "        g1 = self.upsample(self.g1(x))\n",
    "        x1 = self.x1(skip)\n",
    "        psi = self.relu(g1 + x1)  # Element-wise addition\n",
    "        psi = self.sigmoid(self.psi(psi))  # Generate attention weights\n",
    "        return skip * psi  # Element-wise multiplication\n",
    "\n",
    "class UpSampleConcat(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(UpSampleConcat, self).__init__()\n",
    "        self.upsample = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "\n",
    "    def forward(self, x, skip):\n",
    "        x = self.upsample(x)\n",
    "        return torch.cat([x, skip], dim=1)\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(UNet, self).__init__()\n",
    "        self.conv1_rgb = ConvBlock(3, 16)\n",
    "        self.conv1_dem = ConvBlock(1, 8)\n",
    "        self.conv2 = ConvBlock(24, 32)\n",
    "        self.conv3 = ConvBlock(32, 64)\n",
    "        self.conv4 = ConvBlock(64, 128)\n",
    "        self.bottleneck = ConvBlock(128, 256)\n",
    "\n",
    "        self.att4 = AttentionBlock(256, 128)\n",
    "        self.up4 = UpSampleConcat()\n",
    "        self.conv5 = ConvBlock(384, 128)\n",
    "\n",
    "        self.att3 = AttentionBlock(128, 64)\n",
    "        self.up3 = UpSampleConcat()\n",
    "        self.conv6 = ConvBlock(192, 64)\n",
    "\n",
    "        self.att2 = AttentionBlock(64, 32)\n",
    "        self.up2 = UpSampleConcat()\n",
    "        self.conv7 = ConvBlock(96, 32)\n",
    "\n",
    "        self.conv8 = ConvBlock(56, 16)\n",
    "\n",
    "        self.out = nn.Sequential(\n",
    "            nn.Conv2d(16, 1, kernel_size=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x_rgb, x_dem):\n",
    "        c1_rgb = self.conv1_rgb(x_rgb)\n",
    "        c1_dem = self.conv1_dem(x_dem)\n",
    "        combined = torch.cat([c1_rgb, c1_dem], dim=1)\n",
    "\n",
    "        c2 = self.conv2(combined)\n",
    "        p2 = nn.MaxPool2d(kernel_size=2)(c2)\n",
    "\n",
    "        c3 = self.conv3(p2)\n",
    "        p3 = nn.MaxPool2d(kernel_size=2)(c3)\n",
    "\n",
    "        c4 = self.conv4(p3)\n",
    "        p4 = nn.MaxPool2d(kernel_size=2)(c4)\n",
    "\n",
    "        bn = self.bottleneck(p4)\n",
    "\n",
    "        a4 = self.att4(bn, c4)\n",
    "        u4 = self.up4(bn, a4)\n",
    "        c5 = self.conv5(u4)\n",
    "\n",
    "        a3 = self.att3(c5, c3)\n",
    "        u3 = self.up3(c5, a3)\n",
    "        c6 = self.conv6(u3)\n",
    "\n",
    "        a2 = self.att2(c6, c2)\n",
    "        u2 = self.up2(c6, a2)\n",
    "        c7 = self.conv7(u2)\n",
    "\n",
    "        u1 = torch.cat([c7, combined], dim=1) # upsampling not needed here\n",
    "        c8 = self.conv8(u1)\n",
    "\n",
    "        return self.out(c8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3addf640-8b7d-45d8-bd98-ebd10c404be7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-30T15:53:44.595397Z",
     "iopub.status.busy": "2024-12-30T15:53:44.595129Z",
     "iopub.status.idle": "2024-12-30T15:53:44.670847Z",
     "shell.execute_reply": "2024-12-30T15:53:44.669870Z",
     "shell.execute_reply.started": "2024-12-30T15:53:44.595375Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2804da87-7e7c-4c6f-8fa1-71927657d90a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-30T15:53:44.671873Z",
     "iopub.status.busy": "2024-12-30T15:53:44.671582Z",
     "iopub.status.idle": "2024-12-30T15:54:33.213201Z",
     "shell.execute_reply": "2024-12-30T15:54:33.212481Z",
     "shell.execute_reply.started": "2024-12-30T15:53:44.671850Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "data_dir = 'Bijie_dataset/Bijie_dataset'\n",
    "images, dems, masks = load_real_data(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "07a81556-70c2-4b5a-a6e0-0c0180a8553d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-30T15:54:33.214335Z",
     "iopub.status.busy": "2024-12-30T15:54:33.214048Z",
     "iopub.status.idle": "2024-12-30T15:54:34.244871Z",
     "shell.execute_reply": "2024-12-30T15:54:34.244045Z",
     "shell.execute_reply.started": "2024-12-30T15:54:33.214306Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2218, 3, 256, 256]) torch.Size([1, 256, 256]) torch.Size([1, 256, 256])\n",
      "Training data size: 2218\n",
      "Testing data size: 555\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# train-test split\n",
    "X_train_img, X_test_img, X_train_dem, X_test_dem, y_train, y_test = train_test_split(\n",
    "    images, dems, masks, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(X_train_img.shape, X_train_dem[0].shape, y_train[0].shape)\n",
    "\n",
    "# ####### Using only 10% of data locally\n",
    "# def subset_data(X_img, X_dem, y, fraction=0.1):\n",
    "#     subset_size = int(len(X_img) * fraction)\n",
    "#     return X_img[:subset_size], X_dem[:subset_size], y[:subset_size]\n",
    "\n",
    "# X_train_img, X_train_dem, y_train = subset_data(X_train_img, X_train_dem, y_train, fraction=0.1)\n",
    "# X_test_img, X_test_dem, y_test = subset_data(X_test_img, X_test_dem, y_test, fraction=0.1)\n",
    "\n",
    "print(\"Training data size:\", len(X_train_img))\n",
    "print(\"Testing data size:\", len(X_test_img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8216a4fb-7d6e-4d72-b4fd-703f76d2ac3c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-30T15:54:34.246783Z",
     "iopub.status.busy": "2024-12-30T15:54:34.246495Z",
     "iopub.status.idle": "2024-12-30T15:54:34.251878Z",
     "shell.execute_reply": "2024-12-30T15:54:34.251032Z",
     "shell.execute_reply.started": "2024-12-30T15:54:34.246760Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# from torch.utils.data import DataLoader, Dataset\n",
    "# import torch.nn.functional as F\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, images, dems, masks):\n",
    "        self.images = images\n",
    "        self.dems = dems\n",
    "        self.masks = masks\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'image': self.images[idx],\n",
    "            'dem': self.dems[idx],\n",
    "            'mask': self.masks[idx]\n",
    "        }\n",
    "\n",
    "train_dataset = CustomDataset(X_train_img, X_train_dem, y_train)\n",
    "val_dataset = CustomDataset(X_test_img, X_test_dem, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "38800797",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-30T15:54:34.253073Z",
     "iopub.status.busy": "2024-12-30T15:54:34.252826Z",
     "iopub.status.idle": "2024-12-30T15:54:34.479608Z",
     "shell.execute_reply": "2024-12-30T15:54:34.478928Z",
     "shell.execute_reply.started": "2024-12-30T15:54:34.253053Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model = UNet().to(device)\n",
    "epochs = 70\n",
    "best_val_loss = float('inf')\n",
    "best_model_path = 'best_unet_model.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\shrey\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 22\u001b[0m\n\u001b[0;32m     19\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m     20\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m---> 22\u001b[0m     train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     24\u001b[0m train_loss \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(train_loader)\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# Validation loop\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "criterion = nn.BCELoss()  # Binary Cross-Entropy Loss\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0005)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5, verbose=True)\n",
    "\n",
    "# Train loop\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "\n",
    "    for batch in train_loader:\n",
    "        images = batch['image'].to(device)\n",
    "        dems = batch['dem'].to(device)\n",
    "        masks = batch['mask'].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images, dems).squeeze(1)\n",
    "        loss = criterion(outputs.unsqueeze(1), masks)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    train_loss /= len(train_loader)\n",
    "\n",
    "    # Validation loop\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            images = batch['image'].to(device)\n",
    "            dems = batch['dem'].to(device)\n",
    "            masks = batch['mask'].to(device)\n",
    "\n",
    "            outputs = model(images, dems).squeeze(1)\n",
    "            loss = criterion(outputs.unsqueeze(1), masks)\n",
    "\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            # Collect predictions and targets for metric calculation\n",
    "            preds = (outputs > 0.5).cpu().numpy().astype(int)\n",
    "            targets = masks.cpu().numpy().astype(int)\n",
    "            all_preds.append(preds)\n",
    "            all_targets.append(targets)\n",
    "\n",
    "    val_loss /= len(val_loader)\n",
    "\n",
    "    # Flatten lists for metric calculations\n",
    "    all_preds = np.concatenate([pred.flatten() for pred in all_preds])\n",
    "    all_targets = np.concatenate([target.flatten() for target in all_targets])\n",
    "\n",
    "    # Compute metrics\n",
    "    f1 = f1_score(all_targets, all_preds)\n",
    "    iou = jaccard_score(all_targets, all_preds)\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}/{epochs}, Train Loss: {train_loss}, Val Loss: {val_loss}, IoU: {iou}, F1: {f1}\")\n",
    "\n",
    "    # Step the scheduler\n",
    "    scheduler.step(val_loss)\n",
    "\n",
    "    # Save the model if val loss improves\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save(model.state_dict(), best_model_path)\n",
    "        print(f\"Saved best model with val loss: {best_val_loss}\")\n",
    "\n",
    "print(\"Training complete. Best model saved to\", best_model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976bd5cd-f63b-487b-a00b-b3514170b1a7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-30T16:05:58.738088Z",
     "iopub.status.busy": "2024-12-30T16:05:58.737732Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# criterion = nn.BCELoss()  # Binary Cross-Entropy Loss\n",
    "# optimizer = optim.Adam(model.parameters(), lr=0.0005)\n",
    "\n",
    "# # Train loop\n",
    "# for epoch in range(epochs):\n",
    "#     model.train()\n",
    "#     train_loss = 0.0\n",
    "\n",
    "#     for batch in train_loader:\n",
    "#         images = batch['image'].to(device)\n",
    "#         dems = batch['dem'].to(device)\n",
    "#         masks = batch['mask'].to(device)\n",
    "\n",
    "#         optimizer.zero_grad()\n",
    "#         outputs = model(images, dems).squeeze(1)\n",
    "#         loss = criterion(outputs.unsqueeze(1), masks)\n",
    "\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "\n",
    "#         train_loss += loss.item()\n",
    "\n",
    "#     train_loss /= len(train_loader)\n",
    "\n",
    "    # # Validation loop\n",
    "    # model.eval()\n",
    "    # val_loss = 0.0\n",
    "    # all_preds = []\n",
    "    # all_targets = []\n",
    "    # with torch.no_grad():\n",
    "    #     for batch in val_loader:\n",
    "    #         images = batch['image'].to(device)\n",
    "    #         dems = batch['dem'].to(device)\n",
    "    #         masks = batch['mask'].to(device)\n",
    "\n",
    "    #         outputs = model(images, dems).squeeze(1)\n",
    "    #         loss = criterion(outputs.unsqueeze(1), masks)\n",
    "\n",
    "    #         val_loss += loss.item()\n",
    "\n",
    "    #         # Collect predictions and targets for metric calculation\n",
    "    #         preds = (outputs > 0.5).cpu().numpy().astype(int)\n",
    "    #         targets = masks.cpu().numpy().astype(int)\n",
    "    #         # print(len(preds[0]))\n",
    "    #         # print(preds[0])\n",
    "    #         all_preds.append(preds)\n",
    "    #         all_targets.append(targets)\n",
    "\n",
    "    # val_loss /= len(val_loader)\n",
    "\n",
    "    # # Flatten lists for metric calculations\n",
    "    # all_preds = np.concatenate([pred.flatten() for pred in all_preds])\n",
    "    # all_targets = np.concatenate([target.flatten() for target in all_targets])\n",
    "\n",
    "    # # Compute metrics\n",
    "    # # precision = precision_score(all_targets, all_preds)\n",
    "    # # recall = recall_score(all_targets, all_preds)\n",
    "    # f1 = f1_score(all_targets, all_preds)\n",
    "    # iou = jaccard_score(all_targets, all_preds)\n",
    "\n",
    "#     print(f\"Epoch {epoch + 1}/{epochs}, Train Loss: {train_loss}, Val Loss: {val_loss}, IoU: {iou}, f1: {f1}\")\n",
    "\n",
    "#     # Save the model if val loss improves\n",
    "#     if val_loss < best_val_loss:\n",
    "#         best_val_loss = val_loss\n",
    "#         torch.save(model.state_dict(), best_model_path)\n",
    "#         print(f\"Saved best model with val loss: {best_val_loss:.4f}\")\n",
    "\n",
    "# print(\"Training complete. Best model saved to\", best_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e6554fb-ee0d-4e52-b3dc-b4e91b1e30e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "model = UNet().to(device)\n",
    "summary(model, input_size=[(1, 3, 256, 256), (1, 1, 256, 256)]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "362170b4-d6f2-491a-8635-c8abef0dab98",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 6398811,
     "sourceId": 10334130,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30823,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
